from crewai import Agent, Task, Crew, LLM, Process
import os
import sys
from src.config import settings
import yaml
import requests

# Add the project root to the Python path to allow imports from 'src'
current_dir = os.path.dirname(os.path.abspath(__file__))
project_root = os.path.abspath(os.path.join(current_dir, '..'))
sys.path.insert(0, project_root)

# ðŸ”§ FIX: Import the SemanticRetrievalTool
from src.agents.tools.semantic_retrieval_tool import SemanticRetrievalTool
from src.data_pipeline.indexer import indexer  # Needed to ensure index is built

# Define file paths for YAML configurations
BASE_DIR = os.path.dirname(os.path.abspath(__file__))
AGENTS_CONFIG_PATH = os.path.join(BASE_DIR, 'configs', 'agents.yaml')
TASKS_CONFIG_PATH = os.path.join(BASE_DIR, 'configs', 'tasks.yaml')

files = {
    'agents': AGENTS_CONFIG_PATH,
    'tasks': TASKS_CONFIG_PATH
}

# Load configurations from YAML files
configs = {}
for config_type, file_path in files.items():
    with open(file_path, 'r') as file:
        configs[config_type] = yaml.safe_load(file)

# Assign loaded configurations to specific variables
agents_config = configs['agents']
tasks_config = configs['tasks']

from typing import List
from pydantic import BaseModel, Field

# ðŸ”§ FIX: Ensure the RAG pipeline's index is built/loaded
print("Ensuring FAISS index is built/loaded...")
try:
    indexer.index_products()
    print("âœ… FAISS index ready.")
except FileNotFoundError as e:
    print(f"âŒ Error: {e}. Please ensure data/products.json exists.")
    exit(1)
except Exception as e:
    print(f"âŒ Unexpected error during indexer initialization: {e}")
    exit(1)

# ðŸ”§ FIX: Verify environment variables
if not settings.GOOGLE_API_KEY:
    print("âŒ Error: GOOGLE_API_KEY is not set in your .env file.")
    exit(1)
if not settings.GEMINI_MODEL_NAME:
    print("âŒ Error: GEMINI_MODEL_NAME is not set in your .env file.")
    exit(1)

# ðŸ”§ FIX: Usar la misma configuraciÃ³n que el cÃ³digo que funciona
llm = LLM(
    model=settings.GEMINI_MODEL_NAME,  # â† Cambio 1: Usar configuraciÃ³n desde settings
    temperature=0.7,
    api_key=settings.GOOGLE_API_KEY
)
class ProductQueryCrew:
    """
    Orchestrates the Product Query Bot using CrewAI agents and tasks
    configured via YAML files. This class is designed to be instantiated
    and its run_crew method called by the Flask application.
    """

    def __init__(self):
        # Instantiate the tools that agents will use
        self.semantic_retrieval_tool = SemanticRetrievalTool()
     

        # Create Agents using configurations from YAML and assign tools
        self.retriever_agent = Agent(
            config=agents_config['retriever_agent'],
            tools=[self.semantic_retrieval_tool],
            llm=llm
        )

        self.responder_agent = Agent(
            config=agents_config['responder_agent'],
            llm=llm
        )

    def run_crew(self, user_id: str, query: str) -> str:
        """
        Runs the CrewAI pipeline to answer a user's product query.

        Args:
            user_id (str): The ID of the user asking the question.
            query (str): The user's question about a product.

        Returns:
            str: The final answer generated by the Responder Agent.
        """
        # Create Tasks using configurations from YAML and assigned agents
        # The 'description' for tasks can take dynamic values directly from `run_crew`'s `query`.
        retrieve_task = Task(
            description=tasks_config['retrieve_product_context']['description'].format(query=query),
            expected_output=tasks_config['retrieve_product_context']['expected_output'],
            agent=self.retriever_agent,
            tools=[self.semantic_retrieval_tool],
        )

        generate_response_task = Task(
            description=tasks_config['generate_product_response']['description'].format(query=query, context=retrieve_task.output),
            expected_output=tasks_config['generate_product_response']['expected_output'],
            agent=self.responder_agent,
            context_for_tool_execution={
                "query": query, # Pass the original query to the LLM tool
                "context_docs": retrieve_task.output # Pass the output of retrieve_task (list[dict])
            }
        )

        crew = Crew(
            agents=[self.retriever_agent, self.responder_agent],
            tasks=[retrieve_task, generate_response_task],
            verbose=True, # Set to True for detailed logs during execution
            process=Process.sequential # Ensures retrieve_task runs before generate_response_task
        )

        print(f"Starting CrewAI process for user '{user_id}' with query: '{query}'")
        final_result = crew.kickoff(inputs={'query': query, 'user_id': user_id}) # Pass user_id and query as inputs
        print("CrewAI process finished.")
        return str(final_result)

# Instantiate the crew once for easy access by app.py
product_query_crew = ProductQueryCrew()